import argparse
import csv
import json
import random
import re
from datetime import datetime
from pathlib import Path

from openai import OpenAI

# ===== è¨­å®š: OpenAI(=Ollama) ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ =====
client = OpenAI(
    base_url="http://localhost:11434/v1",  # Ollama API
    api_key="ollama",  # ãƒ€ãƒŸãƒ¼ã‚­ãƒ¼
)

# ===== 20ç¨®é¡ã®ã€Œã‚ˆãã‚ã‚‹å¯¾è©±ã‚¿ã‚¤ãƒ—ã€ =====
TASK_TYPES = [
    "ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³äºˆç´„",
    "å¤©æ°—æ¡ˆå†…ï¼ˆç¾åœ¨/ä»Šæ—¥/é€±ï¼‰",
    "æ™‚åˆ»è¡¨æ¤œç´¢ï¼ˆé›»è»Š/ãƒã‚¹ï¼‰",
    "ä¹—æ›æ¡ˆå†…ï¼ˆæœ€çŸ­/å®‰ã„/æœ¬æ•°ï¼‰",
    "ãƒ›ãƒ†ãƒ«äºˆç´„ï¼ˆæ¡ä»¶ãƒ»æ—¥ä»˜ãƒ»äººæ•°ï¼‰",
    "ãƒ•ãƒ©ã‚¤ãƒˆæƒ…å ±ï¼ˆä¾¿å/é…å»¶/åˆ°ç€ï¼‰",
    "ã‚¿ã‚¯ã‚·ãƒ¼é…è»Š/é…è»Šã‚¢ãƒ—ãƒªé€£æº",
    "å•†å“æ¤œç´¢ãƒ»ä¾¡æ ¼æ¯”è¼ƒï¼ˆè²·ã„ç‰©ï¼‰",
    "è¿”å“/è¿”é‡‘æ‰‹ç¶šãã‚µãƒãƒ¼ãƒˆ",
    "ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼äºˆå®šã®ä½œæˆ/ç¢ºèª",
    "ãƒªãƒã‚¤ãƒ³ãƒ€ãƒ¼è¨­å®š/ç®¡ç†",
    "ãƒ‹ãƒ¥ãƒ¼ã‚¹è¦ç´„ã¨æ·±æ˜ã‚ŠQA",
    "ä¸€èˆ¬çŸ¥è­˜QAï¼ˆç™¾ç§‘/è±†çŸ¥è­˜ï¼‰",
    "ç¿»è¨³ï¼ˆçŸ­æ–‡/ç”¨é€”æŒ‡å®šï¼‰",
    "é“æ¡ˆå†…ãƒ»ä½æ‰€/åœ°å›³æ¤œç´¢",
    "ã‚µãƒ–ã‚¹ã‚¯è§£ç´„/ãƒ—ãƒ©ãƒ³å¤‰æ›´æ”¯æ´",
    "æŠ€è¡“ã‚µãƒãƒ¼ãƒˆï¼ˆç°¡æ˜“ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒˆï¼‰",
    "å¥åº·/ç—…é™¢äºˆç´„ï¼ˆç§‘/æ™‚é–“/å ´æ‰€ï¼‰",
    "å®¶äº‹ã‚¿ã‚¹ã‚¯è¨ˆç”»ï¼ˆè²·ã„ç‰©ãƒªã‚¹ãƒˆç­‰ï¼‰",
    "æ—…è¡Œè¨ˆç”»ï¼ˆè¡Œç¨‹/è¦‹ã©ã“ã‚/äºˆç®—ï¼‰",
]


# ===== ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ =====
def build_prompt(task_type: str, target_turns: int = 20) -> str:
    return f"""
ã‚ãªãŸã¯é ¼ã‚Šã«ãªã‚‹AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ã¨éŸ³å£°ã§è©±ã—ã¦ã„ã‚‹ã‚ˆã†ãªè‡ªç„¶ãªæ—¥æœ¬èªä¼šè©±ã‚’ä½œã£ã¦ãã ã•ã„ã€‚

# ä¼šè©±ã‚´ãƒ¼ãƒ«
- å¯¾è©±ã‚¿ã‚¤ãƒ—: ã€Œ{task_type}ã€
- ç›®çš„: ãƒ¦ãƒ¼ã‚¶ãŒã“ã®ã‚¿ã‚¹ã‚¯ã‚’å®Œäº†ã¾ãŸã¯ç†è§£ã§ãã‚‹ã‚ˆã†ã«æ”¯æ´ã™ã‚‹
- ä¼šè©±ã¯æœ€å¤§ã§{target_turns}ç™ºè©±ç¨‹åº¦ï¼ˆå°‘ãªãã¦ã‚‚ã‚ˆã„ï¼‰

# ä¼šè©±ã‚¹ã‚¿ã‚¤ãƒ«
- è©±ã—è¨€è‘‰ã§è‡ªç„¶ã«ã€‚æ–‡ã¯çŸ­ã‚ã§ãƒ†ãƒ³ãƒè‰¯ãã€‚
- ã€Œã€‚ã€ã€Œã€ã€ã€Œï¼Ÿã€ã€Œï¼ã€ãªã©ã®å¥èª­ç‚¹ã¯ä½¿ã£ã¦ã‚ˆã„ã€‚
- é›£ã—ã„æ–‡èªè¡¨ç¾ã¯é¿ã‘ã‚‹ã€‚

# å‡ºåŠ›ä»•æ§˜ï¼ˆæœ€é‡è¦ï¼‰
- **å¿…ãš JSON é…åˆ—ã®ã¿**ã‚’å‡ºåŠ›ï¼ˆèª¬æ˜ã‚„ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã¯å‡ºåŠ›ã—ãªã„ï¼‰ã€‚
- JSON æ§‹æ–‡ï¼ˆ[ ] {{ }} , : "ï¼‰ã¯ä½¿ç”¨ã™ã‚‹ã€‚ãŸã ã— **content ã®ä¸­ã§ã¯ ASCII ã®ãƒ€ãƒ–ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆ " ã¨ ãƒãƒƒã‚¯ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ \\ ã¨ æ”¹è¡Œ ã‚’ä½¿ã‚ãªã„ã€‚**
  - å¼•ç”¨ãŒå¿…è¦ãªã‚‰æ—¥æœ¬èªã®é‰¤æ‹¬å¼§ã€Œã€ã‚’ä½¿ã†ã“ã¨ã€‚
  - content ã¯1è¡Œã§æ›¸ãã“ã¨ï¼ˆ\\n ã‚‚ä¸å¯ï¼‰ã€‚
- å½¢å¼ä¾‹ï¼š
[
  {{"role":"assistant","content":"ã“ã‚“ã«ã¡ã¯ã€‚ä»Šæ—¥ã¯ä½•ã«ã¤ã„ã¦è©±ã—ã¾ã™ã‹ï¼Ÿ"}},
  {{"role":"user","content":"ï¼ˆãƒ¦ãƒ¼ã‚¶ãŒ{task_type}ã®æ„å›³ã‚’è¿°ã¹ã‚‹ï¼‰"}}
]

# ä¼šè©±ã®æµã‚Œ
- æœ€åˆã¯ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãŒã€Œã“ã‚“ã«ã¡ã¯ã€‚ä»Šæ—¥ã¯ä½•ã«ã¤ã„ã¦è©±ã—ã¾ã™ã‹ï¼Ÿã€ã€‚
- ãƒ¦ãƒ¼ã‚¶ã¯æœ€åˆã®ç™ºè©±ã§ {task_type} ã«é–¢ã™ã‚‹è¦ä»¶ã‚’è¿°ã¹ã‚‹ã€‚
- ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã¯ç¢ºèªãƒ»ææ¡ˆãƒ»è¦ç´„ã‚’æŒŸã¿ã¤ã¤ã‚¿ã‚¹ã‚¯ã‚’é€²ã‚ã‚‹ã€‚
- çµ‚ç›¤ã§çµæœã‚’ç¢ºèªã—ã€è‡ªç„¶ã«çµ‚äº†ã™ã‚‹ï¼ˆç„¡ç†ã« {target_turns} ã«åˆã‚ã›ãªã„ï¼‰ã€‚
""".strip()


# ===== ãƒ¢ãƒ‡ãƒ«å‘¼ã³å‡ºã— =====
def generate_dialog(
    task_type: str, model: str = "gpt-oss:20b", turns: int = 20
) -> list[dict]:
    prompt = build_prompt(task_type, turns)
    resp = client.chat.completions.create(
        model=model,
        messages=[
            {
                "role": "system",
                "content": "You are a helpful Japanese-speaking assistant that generates high-quality simulated dialogues (JSON array only).",
            },
            {"role": "user", "content": prompt},
        ],
        temperature=0.9,
        max_tokens=4096,
    )

    content = resp.choices[0].message.content

    try:
        data = json.loads(content)
    except json.JSONDecodeError:
        import re

        content_clean = re.sub(
            r"^```(?:json)?|```$", "", content.strip(), flags=re.MULTILINE
        )
        data = json.loads(content_clean)

    fixed = []
    for m in data:
        if not isinstance(m, dict):
            continue
        role = m.get("role")
        text = m.get("content")
        if role in ("assistant", "user") and isinstance(text, str) and text.strip():
            fixed.append({"role": role, "content": text.strip()})

    # ğŸ‘‡ ã“ã“ã‚’å¤‰æ›´ï¼š
    # ä¸è¶³åˆ†ã‚’å¼·åˆ¶çš„ã«åŸ‹ã‚ãªã„ã€‚ç”Ÿæˆã•ã‚ŒãŸåˆ†ã ã‘ä½¿ã†ã€‚
    # å¿…è¦ãªã‚‰ turns ä¸Šé™ã§åˆ‡ã‚Šæ¨ã¦ã€‚
    if len(fixed) > turns:
        fixed = fixed[:turns]

    return fixed


# ===== TSVä¿å­˜ =====
def save_dialog_as_tsv(
    dialog: list[dict], out_path: Path, task_type: str, meta: dict | None = None
):
    out_path.parent.mkdir(parents=True, exist_ok=True)
    with out_path.open("w", encoding="utf-8", newline="") as f:
        writer = csv.writer(f, delimiter="\t")
        # ãƒ˜ãƒƒãƒ€
        headers = ["turn_index", "role", "content", "task_type"]
        if meta:
            # ãƒ¡ã‚¿æƒ…å ±ã‚’åˆ—ã¨ã—ã¦è¿½åŠ ï¼ˆä¾‹: seed, timestamp, modelï¼‰
            headers.extend(meta.keys())
        writer.writerow(headers)

        # æœ¬æ–‡
        for i, msg in enumerate(dialog, start=1):
            row = [i, msg["role"], msg["content"], task_type]
            if meta:
                row.extend(meta.values())
            writer.writerow(row)


# ===== ãƒ¡ã‚¤ãƒ³ =====
def main():
    parser = argparse.ArgumentParser(
        description="Generate n simulated dialogues and save each as TSV."
    )
    parser.add_argument("--n", type=int, default=1, help="ç”Ÿæˆã™ã‚‹å¯¾è©±æ•°ï¼ˆåˆæœŸå€¤: 1ï¼‰")
    parser.add_argument(
        "--model",
        type=str,
        default="gpt-oss:20b",
        help="ãƒ¢ãƒ‡ãƒ«åï¼ˆåˆæœŸå€¤: gpt-oss:20bï¼‰",
    )
    parser.add_argument(
        "--turns", type=int, default=20, help="1å¯¾è©±ã‚ãŸã‚Šã®ç™ºè©±æ•°ï¼ˆåˆæœŸå€¤: 20ï¼‰"
    )
    parser.add_argument(
        "--outdir", type=str, default="outputs_tsv", help="å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª"
    )
    args = parser.parse_args()

    out_dir = Path(args.outdir)
    now = datetime.now().strftime("%Y%m%d_%H%M%S")

    for i in range(1, args.n + 1):
        # ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—ã‚’é¸æŠ
        task_type = random.choice(TASK_TYPES)

        # ç”Ÿæˆ
        dialog = generate_dialog(
            task_type=task_type, model=args.model, turns=args.turns
        )

        # ãƒ¡ã‚¿æƒ…å ±
        meta = {
            "seed_like": str(random.randint(0, 2**31 - 1)),
            "timestamp": now,
            "model": args.model,
        }

        # ãƒ•ã‚¡ã‚¤ãƒ«å: é€£ç•ª + ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—ã‚¹ãƒ©ãƒƒã‚°
        slug = re.sub(r"[^a-zA-Z0-9]+", "_", task_type).strip("_")
        fname = f"dialog_{i:04d}_{slug}.tsv"
        save_dialog_as_tsv(dialog, out_dir / fname, task_type, meta=meta)

        print(f"âœ… Saved: {out_dir / fname}  (task_type={task_type})")


if __name__ == "__main__":
    main()
